{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5597b834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/anil/hdd2/nihal/gmflow'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "539dc02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  # Use both GPUs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch.nn import init\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import build_train_dataset\n",
    "from gmflow.gmflow import GMFlow\n",
    "from loss import flow_loss_func\n",
    "from evaluate import validate_chairs, validate_things, validate_sintel, validate_kitti\n",
    "from utils.logger import Logger\n",
    "from utils import misc\n",
    "\n",
    "from gmflow.backbone import CNNEncoder\n",
    "from gmflow.transformer import FeatureTransformer, FeatureFlowAttention\n",
    "from gmflow.matching import global_correlation_softmax, local_correlation_softmax\n",
    "from gmflow.geometry import flow_warp\n",
    "from gmflow.utils import normalize_img, feature_add_position\n",
    "from gmflow.trident_conv import MultiScaleTridentConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "109c3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, dilation=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(\n",
    "            in_channels, \n",
    "            in_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=dilation,\n",
    "            groups=in_channels,\n",
    "            dilation=dilation,\n",
    "            bias=False\n",
    "        )\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        scale = self.avg_pool(x)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = self.sigmoid(scale)\n",
    "        return x * scale\n",
    "\n",
    "class ResidualBlockWithSE(nn.Module):\n",
    "    def __init__(self, in_planes, planes, norm_layer=nn.InstanceNorm2d, stride=1, dilation=1):\n",
    "        super(ResidualBlockWithSE, self).__init__()\n",
    "        \n",
    "        self.conv1 = DepthwiseSeparableConv(in_planes, planes, stride=stride, dilation=dilation)\n",
    "        self.conv2 = DepthwiseSeparableConv(planes, planes, dilation=dilation)\n",
    "        \n",
    "        self.norm1 = norm_layer(planes)\n",
    "        self.norm2 = norm_layer(planes)\n",
    "        \n",
    "        self.se = SqueezeExcitation(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if not stride == 1 or in_planes != planes:\n",
    "            self.norm3 = norm_layer(planes)\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride),\n",
    "                self.norm3\n",
    "            )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        \n",
    "        out = self.se(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class EnhancedCNNEncoder(nn.Module):\n",
    "    def __init__(self, output_dim=128, norm_layer=nn.InstanceNorm2d, num_output_scales=1):\n",
    "        super(EnhancedCNNEncoder, self).__init__()\n",
    "        self.num_branch = num_output_scales\n",
    "        \n",
    "        feature_dims = [64, 96, 128]\n",
    "        \n",
    "        # Initial convolution with same parameters as original\n",
    "        self.conv1 = nn.Conv2d(3, feature_dims[0], kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.norm1 = norm_layer(feature_dims[0])\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Create residual blocks\n",
    "        self.in_planes = feature_dims[0]\n",
    "        self.layer1 = self._make_layer(feature_dims[0], stride=1, norm_layer=norm_layer)\n",
    "        self.layer2 = self._make_layer(feature_dims[1], stride=2, norm_layer=norm_layer)\n",
    "        \n",
    "        # Maintain original stride logic\n",
    "        stride = 2 if num_output_scales == 1 else 1\n",
    "        self.layer3 = self._make_layer(feature_dims[2], stride=stride, norm_layer=norm_layer)\n",
    "        \n",
    "        # Final 1x1 conv to match output dimension\n",
    "        self.conv2 = nn.Conv2d(feature_dims[2], output_dim, 1, 1, 0)\n",
    "        \n",
    "        # Initialize Trident Conv if multiple scales needed\n",
    "        if self.num_branch > 1:\n",
    "            if self.num_branch == 4:\n",
    "                strides = (1, 2, 4, 8)\n",
    "            elif self.num_branch == 3:\n",
    "                strides = (1, 2, 4)\n",
    "            elif self.num_branch == 2:\n",
    "                strides = (1, 2)\n",
    "            else:\n",
    "                raise ValueError\n",
    "                \n",
    "            self.trident_conv = MultiScaleTridentConv(\n",
    "                output_dim, \n",
    "                output_dim,\n",
    "                kernel_size=3,\n",
    "                strides=strides,\n",
    "                paddings=1,\n",
    "                num_branch=self.num_branch\n",
    "            )\n",
    "        \n",
    "        # Weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.InstanceNorm2d, nn.GroupNorm)):\n",
    "                if m.weight is not None:\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, dim, stride=1, dilation=1, norm_layer=nn.InstanceNorm2d):\n",
    "        layer1 = ResidualBlockWithSE(self.in_planes, dim, norm_layer=norm_layer, \n",
    "                                   stride=stride, dilation=dilation)\n",
    "        layer2 = ResidualBlockWithSE(dim, dim, norm_layer=norm_layer, \n",
    "                                   stride=1, dilation=dilation)\n",
    "        \n",
    "        layers = (layer1, layer2)\n",
    "        self.in_planes = dim\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.layer1(x)  # 1/2\n",
    "        x = self.layer2(x)  # 1/4\n",
    "        x = self.layer3(x)  # 1/8 or 1/4 depending on num_output_scales\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        if self.num_branch > 1:\n",
    "            out = self.trident_conv([x] * self.num_branch)\n",
    "        else:\n",
    "            out = [x]\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcef3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class DilatedConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, dilation=1):\n",
    "#         super().__init__()\n",
    "#         padding = dilation * (kernel_size - 1) // 2\n",
    "#         self.conv = nn.Conv2d(\n",
    "#             in_channels, \n",
    "#             out_channels,\n",
    "#             kernel_size=kernel_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             dilation=dilation,\n",
    "#             bias=False\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.conv(x)\n",
    "\n",
    "# class ASPP(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         dilations = [1, 6, 12, 18]\n",
    "        \n",
    "#         # Keep channels same as input throughout ASPP\n",
    "#         self.aspp = nn.ModuleList()\n",
    "#         for dilation in dilations:\n",
    "#             self.aspp.append(\n",
    "#                 nn.Sequential(\n",
    "#                     nn.Conv2d(in_channels, in_channels, 1, bias=False),\n",
    "#                     nn.InstanceNorm2d(in_channels),\n",
    "#                     nn.ReLU(inplace=True),\n",
    "#                     DilatedConv(in_channels, in_channels, dilation=dilation),\n",
    "#                     nn.InstanceNorm2d(in_channels),\n",
    "#                     nn.ReLU(inplace=True)\n",
    "#                 )\n",
    "#             )\n",
    "        \n",
    "#         self.global_branch = nn.Sequential(\n",
    "#             nn.AdaptiveAvgPool2d(1),\n",
    "#             nn.Conv2d(in_channels, in_channels, 1, bias=False),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "        \n",
    "#         # Ensure output channels match input\n",
    "#         self.output_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels * 5, out_channels, 1, bias=False),\n",
    "#             nn.InstanceNorm2d(out_channels),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         size = x.size()[2:]\n",
    "        \n",
    "#         res = []\n",
    "#         for aspp_module in self.aspp:\n",
    "#             res.append(aspp_module(x))\n",
    "        \n",
    "#         global_context = self.global_branch(x)\n",
    "#         global_context = F.interpolate(\n",
    "#             global_context,\n",
    "#             size=size,\n",
    "#             mode='bilinear',\n",
    "#             align_corners=False\n",
    "#         )\n",
    "        \n",
    "#         res.append(global_context)\n",
    "#         combined = torch.cat(res, dim=1)\n",
    "        \n",
    "#         return self.output_conv(combined)\n",
    "\n",
    "# class EnhancedResidualBlock(nn.Module):\n",
    "#     def __init__(self, in_planes, planes, norm_layer=nn.InstanceNorm2d, stride=1, dilation=1):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # Keep the same structure as original ResidualBlock\n",
    "#         self.conv1 = DilatedConv(in_planes, planes, stride=stride, dilation=dilation)\n",
    "#         self.conv2 = DilatedConv(planes, planes, dilation=dilation)\n",
    "        \n",
    "#         self.norm1 = norm_layer(planes)\n",
    "#         self.norm2 = norm_layer(planes)\n",
    "        \n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "#         # Match original downsample exactly\n",
    "#         if stride != 1 or in_planes != planes:\n",
    "#             self.norm3 = norm_layer(planes)\n",
    "#             self.downsample = nn.Sequential(\n",
    "#                 nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride),\n",
    "#                 self.norm3\n",
    "#             )\n",
    "#         else:\n",
    "#             self.downsample = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "        \n",
    "#         out = self.conv1(x)\n",
    "#         out = self.norm1(out)\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "#         out = self.conv2(out)\n",
    "#         out = self.norm2(out)\n",
    "        \n",
    "#         if self.downsample is not None:\n",
    "#             identity = self.downsample(x)\n",
    "        \n",
    "#         out += identity\n",
    "#         out = self.relu(out)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "# class EnhancedCNNEncoder(nn.Module):\n",
    "#     def __init__(self, output_dim=128, norm_layer=nn.InstanceNorm2d, num_output_scales=1):\n",
    "#         super().__init__()\n",
    "#         self.num_branch = num_output_scales\n",
    "        \n",
    "#         feature_dims = [64, 96, 128]\n",
    "        \n",
    "#         # Keep original first conv\n",
    "#         self.conv1 = nn.Conv2d(3, feature_dims[0], kernel_size=7, stride=2, padding=3, bias=False)\n",
    "#         self.norm1 = norm_layer(feature_dims[0])\n",
    "#         self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "#         # Main layers\n",
    "#         self.in_planes = feature_dims[0]\n",
    "#         self.layer1 = self._make_layer(feature_dims[0], stride=1, norm_layer=norm_layer)\n",
    "#         self.layer2 = self._make_layer(feature_dims[1], stride=2, norm_layer=norm_layer)\n",
    "        \n",
    "#         # Add ASPP between layer2 and layer3\n",
    "#         self.aspp = ASPP(feature_dims[1], feature_dims[2])  # output: 128 channels\n",
    "        \n",
    "#         # IMPORTANT CHANGE: Update in_planes to match ASPP output\n",
    "#         self.in_planes = feature_dims[2]  # Now 128 channels\n",
    "        \n",
    "#         # layer3 receives output from ASPP (128 channels)\n",
    "#         stride = 2 if num_output_scales == 1 else 1\n",
    "#         self.layer3 = self._make_layer(feature_dims[2], stride=stride, norm_layer=norm_layer)\n",
    "        \n",
    "#         # Final projection\n",
    "#         self.conv2 = nn.Conv2d(feature_dims[2], output_dim, 1, 1, 0)\n",
    "        \n",
    "#         if self.num_branch > 1:\n",
    "#             if self.num_branch == 4:\n",
    "#                 strides = (1, 2, 4, 8)\n",
    "#             elif self.num_branch == 3:\n",
    "#                 strides = (1, 2, 4)\n",
    "#             elif self.num_branch == 2:\n",
    "#                 strides = (1, 2)\n",
    "#             else:\n",
    "#                 raise ValueError\n",
    "            \n",
    "#             self.trident_conv = MultiScaleTridentConv(\n",
    "#                 output_dim, \n",
    "#                 output_dim,\n",
    "#                 kernel_size=3,\n",
    "#                 strides=strides,\n",
    "#                 paddings=1,\n",
    "#                 num_branch=self.num_branch\n",
    "#             )\n",
    "        \n",
    "#         self._initialize_weights()\n",
    "\n",
    "        \n",
    "#     def _initialize_weights(self):\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#             elif isinstance(m, (nn.BatchNorm2d, nn.InstanceNorm2d, nn.GroupNorm)):\n",
    "#                 if m.weight is not None:\n",
    "#                     nn.init.constant_(m.weight, 1)\n",
    "#                 if m.bias is not None:\n",
    "#                     nn.init.constant_(m.bias, 0)\n",
    "\n",
    "#     def _make_layer(self, dim, stride=1, dilation=1, norm_layer=nn.InstanceNorm2d):\n",
    "#         # Create layer with current in_planes (important for proper channel handling)\n",
    "#         layer1 = EnhancedResidualBlock(self.in_planes, dim, norm_layer=norm_layer, \n",
    "#                                      stride=stride, dilation=dilation)\n",
    "#         layer2 = EnhancedResidualBlock(dim, dim, norm_layer=norm_layer, \n",
    "#                                      stride=1, dilation=dilation)\n",
    "        \n",
    "#         self.in_planes = dim\n",
    "#         return nn.Sequential(layer1, layer2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Add dimension prints to debug\n",
    "#         print(f\"Initial input: {x.shape}\")\n",
    "        \n",
    "#         x = self.conv1(x)\n",
    "#         x = self.norm1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         print(f\"After conv1: {x.shape}\")  # Should be [B, 64, H/2, W/2]\n",
    "        \n",
    "#         x = self.layer1(x)\n",
    "#         print(f\"After layer1: {x.shape}\")  # Should be [B, 64, H/2, W/2]\n",
    "        \n",
    "#         x = self.layer2(x)\n",
    "#         print(f\"After layer2: {x.shape}\")  # Should be [B, 96, H/4, W/4]\n",
    "        \n",
    "#         x = self.aspp(x)\n",
    "#         print(f\"After ASPP: {x.shape}\")    # Should be [B, 128, H/4, W/4]\n",
    "        \n",
    "#         x = self.layer3(x)\n",
    "#         print(f\"After layer3: {x.shape}\")  # Should be [B, 128, H/8 or H/4, W/8 or W/4]\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         print(f\"After conv2: {x.shape}\")   # Should be [B, output_dim, H/8 or H/4, W/8 or W/4]\n",
    "        \n",
    "#         if self.num_branch > 1:\n",
    "#             out = self.trident_conv([x] * self.num_branch)\n",
    "#         else:\n",
    "#             out = [x]\n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "668dba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "class SlotAttentionFlow(nn.Module):\n",
    "    def __init__(self, in_channels, iters=3, eps=1e-8):\n",
    "        super(SlotAttentionFlow, self).__init__()\n",
    "        \n",
    "        self.num_slots = 2\n",
    "        self.iters = iters\n",
    "        self.eps = eps\n",
    "        self.scale = in_channels ** -0.5\n",
    "        self.dim = in_channels\n",
    "        \n",
    "        # Feature projections\n",
    "        self.q_proj = nn.Linear(in_channels, in_channels)\n",
    "        self.k_proj = nn.Linear(in_channels, in_channels)\n",
    "        self.v_proj = nn.Linear(in_channels, in_channels)\n",
    "        \n",
    "        # Slot processing\n",
    "        self.slot_init = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels),\n",
    "            nn.LayerNorm(in_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # GRU update\n",
    "        self.gru = nn.GRUCell(in_channels, in_channels)\n",
    "        \n",
    "        # Flow refinement - make it resolution-independent\n",
    "        self.flow_mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 2)  # Output 2D flow per position\n",
    "        )\n",
    "        \n",
    "        # Norms\n",
    "        self.norm_feat = nn.LayerNorm(in_channels)\n",
    "        self.norm_slots = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self._reset_parameters()\n",
    "        \n",
    "    def _reset_parameters(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, feature0, flow, local_window_attn=False, local_window_radius=1):\n",
    "        print(f\"\\nForward input shapes:\")\n",
    "        print(f\"feature0: {feature0.shape}\")\n",
    "        print(f\"flow: {flow.shape}\")\n",
    "        print(f\"local_window_attn: {local_window_attn}\")\n",
    "        \n",
    "        if local_window_attn:\n",
    "            return self.forward_local_window_attn(feature0, flow, local_window_radius)\n",
    "            \n",
    "        b, c, h, w = feature0.size()\n",
    "        print(f\"\\nProcessing global attention with dims b={b}, c={c}, h={h}, w={w}\")\n",
    "        \n",
    "        # Reshape feature for attention\n",
    "        feature = feature0.view(b, c, -1).permute(0, 2, 1)  # [B, H*W, C]\n",
    "        feature = self.norm_feat(feature)\n",
    "        print(f\"Normalized feature shape: {feature.shape}\")\n",
    "        \n",
    "        # Initialize slots from feature\n",
    "        slots = feature.mean(dim=1, keepdim=True)  # [B, 1, C]\n",
    "        slots = self.slot_init(slots)\n",
    "        slots = slots.repeat(1, self.num_slots, 1)  # [B, 2, C]\n",
    "        print(f\"Initial slots shape: {slots.shape}\")\n",
    "        \n",
    "        # Prepare KV\n",
    "        k = self.k_proj(feature)  # [B, H*W, C]\n",
    "        v = self.v_proj(feature)  # [B, H*W, C]\n",
    "        print(f\"K shape: {k.shape}, V shape: {v.shape}\")\n",
    "        \n",
    "        # Iterative refinement\n",
    "        for iter_idx in range(self.iters):\n",
    "            print(f\"\\nIteration {iter_idx + 1}\")\n",
    "            slots_prev = slots\n",
    "            \n",
    "            q = self.q_proj(self.norm_slots(slots))  # [B, 2, C]\n",
    "            print(f\"Query shape: {q.shape}\")\n",
    "            \n",
    "            attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale  # [B, 2, H*W]\n",
    "            attn = F.softmax(attn, dim=-1)\n",
    "            print(f\"Attention shape: {attn.shape}\")\n",
    "            \n",
    "            updates = torch.matmul(attn, v)  # [B, 2, C]\n",
    "            print(f\"Updates shape: {updates.shape}\")\n",
    "            \n",
    "            slots = self.gru(\n",
    "                updates.reshape(-1, self.dim),\n",
    "                slots_prev.reshape(-1, self.dim)\n",
    "            )\n",
    "            slots = slots.reshape(b, self.num_slots, self.dim)\n",
    "            print(f\"Updated slots shape: {slots.shape}\")\n",
    "        \n",
    "        # Process each position with the slot features\n",
    "        feature_with_slots = feature + torch.matmul(attn.transpose(-2, -1), slots)  # [B, H*W, C]\n",
    "        flow_updates = self.flow_mlp(feature_with_slots)  # [B, H*W, 2]\n",
    "        flow_updates = flow_updates.permute(0, 2, 1).view(b, 2, h, w)  # [B, 2, H, W]\n",
    "        \n",
    "        print(f\"\\nFlow updates shape: {flow_updates.shape}\")\n",
    "        print(f\"Input flow shape: {flow.shape}\")\n",
    "        \n",
    "        refined_flow = flow + flow_updates\n",
    "        print(f\"Refined flow shape: {refined_flow.shape}\")\n",
    "        \n",
    "        return refined_flow\n",
    "    \n",
    "    def forward_local_window_attn(self, feature0, flow, local_window_radius):\n",
    "        b, c, h, w = feature0.size()\n",
    "        print(f\"\\nLocal window attention - input dims: b={b}, c={c}, h={h}, w={w}\")\n",
    "        \n",
    "        kernel_size = 2 * local_window_radius + 1\n",
    "        print(f\"Kernel size: {kernel_size}\")\n",
    "        \n",
    "        # Process features\n",
    "        feature = feature0.view(b, c, -1).permute(0, 2, 1).contiguous()  # [B, H*W, C]\n",
    "        feature = self.norm_feat(feature)\n",
    "        print(f\"Normalized feature shape: {feature.shape}\")\n",
    "        \n",
    "        # Initialize slots\n",
    "        slots = feature.mean(dim=1, keepdim=True)  # [B, 1, C]\n",
    "        slots = self.slot_init(slots)\n",
    "        slots = slots.repeat(1, self.num_slots, 1)  # [B, 2, C]\n",
    "        print(f\"Initial slots shape: {slots.shape}\")\n",
    "        \n",
    "        # Process local windows\n",
    "        for iter_idx in range(self.iters):\n",
    "            print(f\"\\nLocal iteration {iter_idx + 1}\")\n",
    "            \n",
    "            q = self.q_proj(self.norm_slots(slots))  # [B, 2, C]\n",
    "            k = self.k_proj(feature)  # [B, H*W, C]\n",
    "            print(f\"Query shape: {q.shape}, Key shape: {k.shape}\")\n",
    "            \n",
    "            attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale  # [B, 2, H*W]\n",
    "            attn = F.softmax(attn, dim=-1)\n",
    "            print(f\"Attention shape: {attn.shape}\")\n",
    "            \n",
    "            updates = torch.matmul(attn, k)  # [B, 2, C]\n",
    "            print(f\"Updates shape: {updates.shape}\")\n",
    "            \n",
    "            slots = self.gru(\n",
    "                updates.reshape(-1, self.dim),\n",
    "                slots.reshape(-1, self.dim)\n",
    "            )\n",
    "            slots = slots.reshape(b, self.num_slots, self.dim)\n",
    "            print(f\"Updated slots shape: {slots.shape}\")\n",
    "        \n",
    "        # Process each position with the slot features\n",
    "        feature_with_slots = feature + torch.matmul(attn.transpose(-2, -1), slots)  # [B, H*W, C]\n",
    "        flow_updates = self.flow_mlp(feature_with_slots)  # [B, H*W, 2]\n",
    "        flow_updates = flow_updates.permute(0, 2, 1).view(b, 2, h, w)  # [B, 2, H, W]\n",
    "        \n",
    "        print(f\"\\nFlow updates shape: {flow_updates.shape}\")\n",
    "        \n",
    "        refined_flow = flow + flow_updates\n",
    "        print(f\"Final refined flow shape: {refined_flow.shape}\")\n",
    "        \n",
    "        return refined_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86193a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMFlow(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_scales=1,\n",
    "                 upsample_factor=8,\n",
    "                 feature_channels=128,\n",
    "                 attention_type='swin',\n",
    "                 num_transformer_layers=6,\n",
    "                 ffn_dim_expansion=4,\n",
    "                 num_head=1,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super(GMFlow, self).__init__()\n",
    "\n",
    "        self.num_scales = num_scales\n",
    "        self.feature_channels = feature_channels\n",
    "        self.upsample_factor = upsample_factor\n",
    "        self.attention_type = attention_type\n",
    "        self.num_transformer_layers = num_transformer_layers\n",
    "\n",
    "        # CNN backbone\n",
    "#         self.backbone = CNNEncoder(output_dim=feature_channels, num_output_scales=num_scales)\n",
    "        self.backbone = EnhancedCNNEncoder(output_dim=feature_channels, num_output_scales=num_scales)\n",
    "        # Transformer\n",
    "        self.transformer = FeatureTransformer(num_layers=num_transformer_layers,\n",
    "                                              d_model=feature_channels,\n",
    "                                              nhead=num_head,\n",
    "                                              attention_type=attention_type,\n",
    "                                              ffn_dim_expansion=ffn_dim_expansion,\n",
    "                                              )\n",
    "\n",
    "        # flow propagation with self-attn\n",
    "#         self.feature_flow_attn = FeatureFlowAttention(in_channels=feature_channels)\n",
    "        self.feature_flow_attn = SlotAttentionFlow(\n",
    "            in_channels=feature_channels,\n",
    "            iters=3  # adjust based on your needs\n",
    "        )       \n",
    "        # convex upsampling: concat feature0 and flow as input\n",
    "        self.upsampler = nn.Sequential(nn.Conv2d(2 + feature_channels, 256, 3, 1, 1),\n",
    "                                       nn.ReLU(inplace=True),\n",
    "                                       nn.Conv2d(256, upsample_factor ** 2 * 9, 1, 1, 0))\n",
    "\n",
    "    def extract_feature(self, img0, img1):\n",
    "        concat = torch.cat((img0, img1), dim=0)  # [2B, C, H, W]\n",
    "        features = self.backbone(concat)  # list of [2B, C, H, W], resolution from high to low\n",
    "\n",
    "        # reverse: resolution from low to high\n",
    "        features = features[::-1]\n",
    "\n",
    "        feature0, feature1 = [], []\n",
    "\n",
    "        for i in range(len(features)):\n",
    "            feature = features[i]\n",
    "            chunks = torch.chunk(feature, 2, 0)  # tuple\n",
    "            feature0.append(chunks[0])\n",
    "            feature1.append(chunks[1])\n",
    "\n",
    "        return feature0, feature1\n",
    "\n",
    "    def upsample_flow(self, flow, feature, bilinear=False, upsample_factor=8,\n",
    "                      ):\n",
    "        if bilinear:\n",
    "            up_flow = F.interpolate(flow, scale_factor=upsample_factor,\n",
    "                                    mode='bilinear', align_corners=True) * upsample_factor\n",
    "\n",
    "        else:\n",
    "            # convex upsampling\n",
    "            concat = torch.cat((flow, feature), dim=1)\n",
    "\n",
    "            mask = self.upsampler(concat)\n",
    "            b, flow_channel, h, w = flow.shape\n",
    "            mask = mask.view(b, 1, 9, self.upsample_factor, self.upsample_factor, h, w)  # [B, 1, 9, K, K, H, W]\n",
    "            mask = torch.softmax(mask, dim=2)\n",
    "\n",
    "            up_flow = F.unfold(self.upsample_factor * flow, [3, 3], padding=1)\n",
    "            up_flow = up_flow.view(b, flow_channel, 9, 1, 1, h, w)  # [B, 2, 9, 1, 1, H, W]\n",
    "\n",
    "            up_flow = torch.sum(mask * up_flow, dim=2)  # [B, 2, K, K, H, W]\n",
    "            up_flow = up_flow.permute(0, 1, 4, 2, 5, 3)  # [B, 2, K, H, K, W]\n",
    "            up_flow = up_flow.reshape(b, flow_channel, self.upsample_factor * h,\n",
    "                                      self.upsample_factor * w)  # [B, 2, K*H, K*W]\n",
    "\n",
    "        return up_flow\n",
    "\n",
    "    def forward(self, img0, img1,\n",
    "                attn_splits_list=None,\n",
    "                corr_radius_list=None,\n",
    "                prop_radius_list=None,\n",
    "                pred_bidir_flow=False,\n",
    "                **kwargs,\n",
    "                ):\n",
    "\n",
    "        results_dict = {}\n",
    "        flow_preds = []\n",
    "\n",
    "        img0, img1 = normalize_img(img0, img1)  # [B, 3, H, W]\n",
    "\n",
    "        # resolution low to high\n",
    "        feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features\n",
    "\n",
    "        flow = None\n",
    "\n",
    "        assert len(attn_splits_list) == len(corr_radius_list) == len(prop_radius_list) == self.num_scales\n",
    "\n",
    "        for scale_idx in range(self.num_scales):\n",
    "            feature0, feature1 = feature0_list[scale_idx], feature1_list[scale_idx]\n",
    "\n",
    "            if pred_bidir_flow and scale_idx > 0:\n",
    "                # predicting bidirectional flow with refinement\n",
    "                feature0, feature1 = torch.cat((feature0, feature1), dim=0), torch.cat((feature1, feature0), dim=0)\n",
    "\n",
    "            upsample_factor = self.upsample_factor * (2 ** (self.num_scales - 1 - scale_idx))\n",
    "\n",
    "            if scale_idx > 0:\n",
    "                flow = F.interpolate(flow, scale_factor=2, mode='bilinear', align_corners=True) * 2\n",
    "            print(f\"shape of feature1: {feature1.shape}\")\n",
    "            if flow is not None:\n",
    "                flow = flow.detach()\n",
    "                feature1 = flow_warp(feature1, flow)  # [B, C, H, W]\n",
    "\n",
    "            attn_splits = attn_splits_list[scale_idx]\n",
    "            corr_radius = corr_radius_list[scale_idx]\n",
    "            prop_radius = prop_radius_list[scale_idx]\n",
    "\n",
    "            # add position to features\n",
    "            feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)\n",
    "\n",
    "            # Transformer\n",
    "            feature0, feature1 = self.transformer(feature0, feature1, attn_num_splits=attn_splits)\n",
    "\n",
    "            # correlation and softmax\n",
    "            if corr_radius == -1:  # global matching\n",
    "                flow_pred = global_correlation_softmax(feature0, feature1, pred_bidir_flow)[0]\n",
    "            else:  # local matching\n",
    "                flow_pred = local_correlation_softmax(feature0, feature1, corr_radius)[0]\n",
    "\n",
    "            # flow or residual flow\n",
    "            flow = flow + flow_pred if flow is not None else flow_pred\n",
    "\n",
    "            # upsample to the original resolution for supervison\n",
    "            if self.training:  # only need to upsample intermediate flow predictions at training time\n",
    "                flow_bilinear = self.upsample_flow(flow, None, bilinear=True, upsample_factor=upsample_factor)\n",
    "                flow_preds.append(flow_bilinear)\n",
    "\n",
    "            # flow propagation with self-attn\n",
    "            if pred_bidir_flow and scale_idx == 0:\n",
    "                feature0 = torch.cat((feature0, feature1), dim=0)  # [2*B, C, H, W] for propagation\n",
    "            flow = self.feature_flow_attn(feature0, flow.detach(),\n",
    "                                          local_window_attn=prop_radius > 0,\n",
    "                                          local_window_radius=prop_radius)\n",
    "\n",
    "            # bilinear upsampling at training time except the last one\n",
    "            if self.training and scale_idx < self.num_scales - 1:\n",
    "                flow_up = self.upsample_flow(flow, feature0, bilinear=True, upsample_factor=upsample_factor)\n",
    "                flow_preds.append(flow_up)\n",
    "\n",
    "            if scale_idx == self.num_scales - 1:\n",
    "                flow_up = self.upsample_flow(flow, feature0)\n",
    "                flow_preds.append(flow_up)\n",
    "\n",
    "        results_dict.update({'flow_preds': flow_preds})\n",
    "\n",
    "        return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce3707ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--checkpoint_dir', default='checkpoints/gmflow_with_refine', type=str)\n",
    "    parser.add_argument('--stage', default='chairs', type=str)\n",
    "    parser.add_argument('--image_size', default=[384, 512], type=int, nargs='+')\n",
    "    parser.add_argument('--padding_factor', default=32, type=int)\n",
    "    parser.add_argument('--num_scales', default=2, type=int)\n",
    "    parser.add_argument('--attn_splits_list', default=[2, 8], type=int, nargs='+')\n",
    "    parser.add_argument('--corr_radius_list', default=[-1, 4], type=int, nargs='+')\n",
    "    parser.add_argument('--prop_radius_list', default=[-1, 1], type=int, nargs='+')\n",
    "    parser.add_argument('--num_steps', default=100000, type=int)\n",
    "    parser.add_argument('--batch_size', default=2, type=int)\n",
    "    parser.add_argument('--lr', default=4e-4, type=float)\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float)\n",
    "    parser.add_argument('--gamma', default=0.9, type=float)\n",
    "#     parser.add_argument('--image_size', default=[384, 512], type=int, nargs='+')\n",
    "    # Add other necessary arguments from the original script\n",
    "    args = parser.parse_args([])  # Parse empty list to use defaults\n",
    "    return args\n",
    "\n",
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e404689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GMFlow(num_scales=args.num_scales,\n",
    "               feature_channels=128,\n",
    "               upsample_factor=4,\n",
    "               num_head=1,\n",
    "               attention_type='swin',\n",
    "               ffn_dim_expansion=4,\n",
    "               num_transformer_layers=6)\n",
    "\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, args.lr, args.num_steps + 10,\n",
    "                                                pct_start=0.05, cycle_momentum=False, anneal_strategy='cos')\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "204d2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 3999382\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    " \n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model = model.module\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\") #3697524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d94e463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = build_train_dataset(args)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "55648e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_writer = SummaryWriter(args.checkpoint_dir)\n",
    "logger = Logger(scheduler, summary_writer, summary_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfe0aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    model.train()\n",
    "    for i, sample in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}', unit='batch')):\n",
    "        img1, img2, flow_gt, valid = [x.cuda() for x in sample]\n",
    "        \n",
    "        results_dict = model(img1, img2,\n",
    "                             attn_splits_list=args.attn_splits_list,\n",
    "                             corr_radius_list=args.corr_radius_list,\n",
    "                             prop_radius_list=args.prop_radius_list)\n",
    "        \n",
    "        flow_preds = results_dict['flow_preds']\n",
    "        \n",
    "        loss, metrics = flow_loss_func(flow_preds, flow_gt, valid, gamma=args.gamma)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        logger.push(metrics)\n",
    "        logger.add_image_summary(img1, img2, flow_preds, flow_gt)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            tqdm.write(f\"Epoch {epoch}, Step {i}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbcfaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce24a12fdfa490f9ac4f8aedd6a499a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/11116 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Epoch 0, Step 0, Loss: 315.5623779296875\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 48, 64])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 48, 64])\n",
      "flow: torch.Size([1, 2, 48, 64])\n",
      "local_window_attn: False\n",
      "\n",
      "Processing global attention with dims b=1, c=128, h=48, w=64\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Normalized feature shape: torch.Size([1, 3072, 128])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "K shape: torch.Size([1, 3072, 128]), V shape: torch.Size([1, 3072, 128])\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 2\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Iteration 3\n",
      "Query shape: torch.Size([1, 2, 128])\n",
      "Attention shape: torch.Size([1, 2, 3072])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 48, 64])\n",
      "Input flow shape: torch.Size([1, 2, 48, 64])\n",
      "Refined flow shape: torch.Size([1, 2, 48, 64])\n",
      "shape of feature1: torch.Size([1, 128, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n",
      "\n",
      "Forward input shapes:\n",
      "feature0: torch.Size([1, 128, 96, 128])\n",
      "flow: torch.Size([1, 2, 96, 128])\n",
      "local_window_attn: True\n",
      "\n",
      "Local window attention - input dims: b=1, c=128, h=96, w=128\n",
      "Kernel size: 3\n",
      "Normalized feature shape: torch.Size([1, 12288, 128])\n",
      "Initial slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 1\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 2\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Local iteration 3\n",
      "Query shape: torch.Size([1, 2, 128]), Key shape: torch.Size([1, 12288, 128])\n",
      "Attention shape: torch.Size([1, 2, 12288])\n",
      "Updates shape: torch.Size([1, 2, 128])\n",
      "Updated slots shape: torch.Size([1, 2, 128])\n",
      "\n",
      "Flow updates shape: torch.Size([1, 2, 96, 128])\n",
      "Final refined flow shape: torch.Size([1, 2, 96, 128])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = args.num_steps // len(train_loader) + 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_epoch(epoch)\n",
    "    \n",
    "    # Validation\n",
    "    if epoch % 10 == 0:  # Adjust validation frequency as needed\n",
    "        results = {}\n",
    "        results.update(validate_chairs(model))\n",
    "        results.update(validate_things(model))\n",
    "        results.update(validate_sintel(model))\n",
    "        results.update(validate_kitti(model))\n",
    "        logger.write_dict(results)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:  # Adjust saving frequency as needed\n",
    "        torch.save({\n",
    "            'model': model.module.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "        }, f'{args.checkpoint_dir}/checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04e929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d1a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gmflow)",
   "language": "python",
   "name": "gmflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
